# GNN-BFS: Graph Neural Network for OpenFOAM Flow Simulation

This project implements a Graph Neural Network (GNN) for training on OpenFOAM flow simulation data, specifically for Backward-Facing Step (BFS) flow cases.

**Latest Update**: Model architecture has been improved with residual connections to ensure predictions maintain correct scale. If you have an old checkpoint, please retrain the model (see [IMPORTANT_RETRAIN.md](IMPORTANT_RETRAIN.md)).

## Overview

The project provides:
- **OpenFOAM Data Parser**: Extracts mesh connectivity and field data from OpenFOAM case directories
- **Graph Construction**: Builds PyTorch Geometric graphs from mesh topology
- **GNN Models**: 
  - Static GNN for single time-step prediction
  - Temporal GNN with LSTM for sequence-to-sequence prediction
- **Training Pipeline**: Complete training script with validation and checkpointing
- **Inference Script**: Make predictions with trained models

## Installation

1. Create a virtual environment (recommended):
```bash
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux
# or
venv\Scripts\activate  # On Windows
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

Note: If you encounter "externally-managed-environment" error, use a virtual environment as shown above. If `pip` is not found, use `pip3` or `python3 -m pip`.

2. Ensure you have OpenFOAM data in the `BFS-OpenFOAM-data/` directory with the following structure:
```
BFS-OpenFOAM-data/
├── constant/
│   └── polyMesh/
│       ├── points
│       ├── owner
│       ├── neighbour
│       └── ...
├── 0/
├── 0.001/
├── 0.002/
└── ...
```

## Usage

### Training

**Important:** Activate the virtual environment first:
```bash
source venv/bin/activate  # On macOS/Linux
```

Train a static GNN model:
```bash
python train.py --data_dir BFS-OpenFOAM-data --epochs 50 --batch_size 4 --model_type static
```

Train a temporal GNN model (recommended for time-series prediction):
```bash
python train.py --data_dir BFS-OpenFOAM-data --epochs 50 --batch_size 4 --model_type temporal --sequence_length 3
```

**Recommended configuration for better results:**
```bash
python train.py \
    --data_dir BFS-OpenFOAM-data \
    --epochs 100 \
    --batch_size 4 \
    --model_type temporal \
    --sequence_length 5 \
    --hidden_dim 128 \
    --num_layers 4 \
    --lr 0.0005
```

Key arguments:
- `--data_dir`: Path to OpenFOAM data directory
- `--epochs`: Number of training epochs
- `--batch_size`: Batch size for training
- `--model_type`: `static` or `temporal`
- `--sequence_length`: Input sequence length for temporal model (default: 3, use 6 for enhanced model)
- `--hidden_dim`: Hidden dimension (default: 64)
- `--num_layers`: Number of GNN layers (default: 3)
- `--layer_type`: GNN layer type: `GCN`, `GAT`, `GIN`, or `attention` (default: GCN)
- `--lr`: Learning rate (default: 0.001)
- `--train_split`: Train/validation split ratio (default: 0.8)
- `--adaptive_sampling`: Use adaptive spatial sampling for graph edges (improves gradient capture)
- `--sampling_radius`: Radius for adaptive sampling (default: auto-computed)
- `--include_coordinates`: Embed cell center coordinates in node features
- `--use_enhanced_model`: Use enhanced model with custom attention architecture
- `--use_flattened_input`: Use flattened sequence input (cylinder project method)

### Prediction

**Important:** Activate the virtual environment first:
```bash
source venv/bin/activate  # On macOS/Linux
```

Make predictions with a trained model:
```bash
python predict.py --checkpoint checkpoints/best_model.pt --data_dir BFS-OpenFOAM-data --visualize
```

Arguments:
- `--checkpoint`: Path to model checkpoint
- `--data_dir`: Path to OpenFOAM data directory
- `--time_dir`: Specific time directory to predict (optional)
- `--output_dir`: Directory to save predictions (default: predictions)
- `--visualize`: Create visualization plots

### Visualization

#### Contour Plots (Pressure & Velocity in X-Y Coordinates)

To plot contour plots showing spatial distribution of pressure and velocity fields:

```bash
python plot_contours.py --checkpoint checkpoints/best_model.pt --data_dir BFS-OpenFOAM-data
```

This creates:
- **Pressure contours**: Vertically stacked comparison of OpenFOAM pressure, model prediction, and error
- **Velocity contours**: Vertically stacked comparison of OpenFOAM velocity magnitude, model prediction, and error
- All plots show spatial distribution in x-y coordinates with contour lines
- **Domain masking**: Uses Delaunay triangulation to preserve sharp boundaries and square corners
- **Same colorbar scale**: OpenFOAM and prediction use identical scales for direct comparison

Options:
- `--time_dir`: Specific time directory to plot (default: validation time step)
- `--output_dir`: Directory to save plots (default: contour_plots)
- `--levels`: Number of contour levels (default: 30)

#### Field Comparison Plots (Pressure & Velocity)

To plot pressure and velocity from both OpenFOAM data and trained model results with error analysis:

```bash
python plot_fields.py --checkpoint checkpoints/best_model.pt --data_dir BFS-OpenFOAM-data
```

This creates:
- **Pressure comparison**: Scatter plots, error distributions, R² scores for pressure
- **Velocity comparison**: Velocity magnitude and component-wise (Ux, Uy, Uz) analysis
- **Error summary**: Comprehensive error statistics and comparisons

Options:
- `--time_dir`: Specific time directory to plot (default: validation time step)
- `--output_dir`: Directory to save plots (default: field_plots)

#### Advanced Visualizations

For comprehensive visualizations with multiple plot types:

```bash
python visualize.py --checkpoint checkpoints/best_model.pt --data_dir BFS-OpenFOAM-data --all
```

This creates:
- **Field comparison plots**: Scatter plots, error distributions, R² scores
- **Component-wise plots**: Separate analysis for Ux, Uy, Uz components
- **Vector field plots**: 2D velocity field visualizations with quiver plots

Options:
- `--all`: Create all visualization types
- `--visualize_field`: Create field comparison plots
- `--visualize_components`: Create component-wise plots
- `--visualize_vectors`: Create vector field plots
- `--time_dir`: Specific time directory to visualize
- `--output_dir`: Directory to save visualizations (default: visualizations)

## Model Architecture

### Static FlowGNN
- Input: Node features (velocity, pressure, etc.)
- Architecture: Multi-layer GCN/GAT/GIN with residual connections
- Output: Predicted field values at next time step
- **Key Feature**: Uses residual connections to predict increments (delta) from input, preserving scale

### Temporal FlowGNN
- Input: Sequence of node features
- Architecture: Spatial GNN + Temporal LSTM
- Output: Predicted field sequence
- **Key Feature**: Predicts increments (delta) from last input state: `output = input + delta`
- This ensures predictions maintain the correct scale (pressure ~15-375, velocity ~0-17)

### Architecture Details

Both models use:
- **Residual connections**: Predict changes rather than absolute values
- **Scale preservation**: Outputs maintain input scale automatically
- **Proper initialization**: Output layers initialized to predict small increments initially

### Adaptive Spatial Sampling (Advanced)

The graph construction supports **adaptive spatial sampling** inspired by multi-scale gradient aggregation methods:

- **Formula**: `ne[i] = {j | (x_j - x_i)² + (y_j - y_i)² < r²}`
- **Purpose**: Captures multi-scale gradient information, especially in regions with large gradient changes (near walls, obstacles)
- **Benefits**: 
  - Prevents jitter in flow fields with large gradient changes
  - Aggregates information from many neighbor nodes in high-gradient regions
  - Better perception of drastic gradient changes

**Usage:**
```bash
python train.py --data_dir BFS-OpenFOAM-data --epochs 50 --adaptive_sampling
```

Or with custom radius:
```bash
python train.py --data_dir BFS-OpenFOAM-data --epochs 50 --adaptive_sampling --sampling_radius 0.002
```

### Enhanced Model with Custom Attention Architecture

The project includes an **enhanced model** based on cylinder project methodology with custom attention mechanisms:

- **Single-headed attention**: Aggregated query from neighbors, key from current node
- **Multi-headed attention**: 4 heads with K and Q dimension = 1
- **Residual connections**: Between attention layers and every 2 layers
- **Flattened sequence input**: `x_i = [u_i[t1:t6], v_i[t1:t6], p_i[t1:t6], ...]`
- **Explicit neighbor aggregation**: `sum(x_j for j in neighbors[i])`

**Usage:**
```bash
python train.py \
    --data_dir BFS-OpenFOAM-data \
    --epochs 100 \
    --model_type temporal \
    --sequence_length 6 \
    --use_enhanced_model \
    --use_flattened_input \
    --include_coordinates \
    --adaptive_sampling \
    --layer_type attention
```

See [ATTENTION_ARCHITECTURE.md](ATTENTION_ARCHITECTURE.md) for detailed architecture documentation.

For detailed theoretical background and methodology, see [METHODOLOGY.md](METHODOLOGY.md).

## Data Format

The parser expects OpenFOAM field files with:
- Vector fields (e.g., `U`): 3D velocity vectors
- Scalar fields (e.g., `p`): Pressure values

Each time directory should contain field files with `internalField` data.

## Output

Training produces:
- Model checkpoints in `checkpoints/` directory
- Training curves plot (`training_curves.png`)

Prediction produces:
- NumPy arrays with predictions and ground truth
- Visualization plots (if `--visualize` is used)

## Important Notes

### Model Architecture Update

⚠️ **If you have an old checkpoint**, you need to retrain the model because the architecture was updated to fix scaling issues. The model now uses residual connections to predict increments, ensuring predictions maintain the correct scale.

See [IMPORTANT_RETRAIN.md](IMPORTANT_RETRAIN.md) for details.

### Technical Details

- **Mesh connectivity**: Built from `owner` and `neighbour` arrays
- **Graph edges**: Internal faces create bidirectional edges
- **Node features**: Velocity (3D) and pressure (1D) by default
- **Cell centers**: Computed accurately from mesh geometry (faces and points) using unique vertices
- **Prediction**: Model predicts the next time step (t+1) from input sequence ending at time t
- **Domain masking**: Contour plots use Delaunay triangulation to preserve sharp boundaries
- **Coordinate embedding**: Optional cell center coordinates can be embedded in features
- **Attention mechanism**: Custom attention with aggregated query from neighbors (see [ATTENTION_ARCHITECTURE.md](ATTENTION_ARCHITECTURE.md))

## Training Guide

For detailed training instructions, see [TRAINING_GUIDE.md](TRAINING_GUIDE.md)

**Quick start:**
```bash
source venv/bin/activate
python train.py --data_dir BFS-OpenFOAM-data --epochs 50 --model_type temporal
```

**Recommended configuration:**
```bash
python train.py \
    --data_dir BFS-OpenFOAM-data \
    --epochs 100 \
    --batch_size 4 \
    --model_type temporal \
    --sequence_length 5 \
    --hidden_dim 128 \
    --num_layers 4 \
    --lr 0.0005
```

## Visualization Guide

**Quick reference:**
- **Contour plots**: `python plot_contours.py --checkpoint checkpoints/best_model.pt --data_dir BFS-OpenFOAM-data`
- **Field comparisons**: `python plot_fields.py --checkpoint checkpoints/best_model.pt --data_dir BFS-OpenFOAM-data`
- **All visualizations**: `python visualize.py --checkpoint checkpoints/best_model.pt --data_dir BFS-OpenFOAM-data --all`
- Additional fields can be added by modifying the `fields` parameter in `graph_constructor.py`
