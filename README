# GNN-BFS: Graph Neural Network for OpenFOAM Flow Simulation

This project implements a Graph Neural Network (GNN) for training on OpenFOAM flow simulation data, specifically for Backward-Facing Step (BFS) flow cases. The implementation strictly follows the method specification with fixed 6-time-step input, exact GAT formula, multi-head attention, and residual connections.

## Overview

The project provides:
- **OpenFOAM Data Parser**: Extracts mesh connectivity and field data from OpenFOAM case directories
- **Graph Construction**: Builds graphs from mesh topology with adaptive spatial sampling
- **GNN Models**: 
  - Static GNN for single time-step prediction
  - Temporal GNN for sequence-to-sequence prediction
- **Training Pipeline**: Complete training script with validation and checkpointing
- **Inference Script**: Make predictions with trained models
- **Visualization Tools**: Contour plots, field comparisons, and error analysis

## Method Specification

This implementation follows the exact method specification:
- **Input**: 6 previous time steps flattened per node: `x_i^(t-1:t-6) = [c_i, p_i, u_i, v_i]_(t-1:t-6)` → 24 features
- **Output**: Next time step: `y_i^t = [c_i, p_i, u_i, v_i]_t` → 4 features
- **GAT Formula**: Exact attention mechanism with Q, K, V projections
- **Multi-Head Attention**: 4 heads with K and Q dimension = 1
- **Residual Connections**: Between layers for stable deep training
- **Loss Function**: MSE (`L = ||y_pred - y_CFD||_2^2`)

For detailed method equations and theory, see [METHOD_SUMMARY.md](METHOD_SUMMARY.md).

## Installation

1. Create a virtual environment (recommended):
```bash
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux
# or
venv\Scripts\activate  # On Windows
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

Note: If you encounter "externally-managed-environment" error, use a virtual environment as shown above. If `pip` is not found, use `pip3` or `python3 -m pip`.

3. Ensure you have OpenFOAM data in the `BFS-OpenFOAM-data/` directory with the following structure:
```
BFS-OpenFOAM-data/
├── constant/
│   └── polyMesh/
│       ├── points
│       ├── owner
│       ├── neighbour
│       └── ...
├── 0/
├── 0.001/
├── 0.002/
└── ...
```

## Usage

### Training

**Important:** Activate the virtual environment first:
```bash
source venv/bin/activate  # On macOS/Linux
```

Train a static GNN model:
```bash
python train_method.py --data_dir BFS-OpenFOAM-data --epochs 50 --batch_size 4 --model_type static
```

Train a temporal GNN model (recommended for time-series prediction):
```bash
python train_method.py --data_dir BFS-OpenFOAM-data --epochs 50 --batch_size 4 --model_type temporal
```

**Recommended configuration:**
```bash
python train_method.py \
    --data_dir BFS-OpenFOAM-data \
    --epochs 100 \
    --batch_size 4 \
    --model_type temporal \
    --hidden_dim 64 \
    --num_layers 4 \
    --lr 0.001 \
    --adaptive_sampling \
    --normalize \
    --normalize_per_field
```

Key arguments:
- `--data_dir`: Path to OpenFOAM data directory
- `--epochs`: Number of training epochs
- `--batch_size`: Batch size for training
- `--model_type`: `static` or `temporal`
- `--hidden_dim`: Hidden dimension (default: 64)
- `--num_layers`: Number of GNN layers (default: 4)
- `--lr`: Learning rate (default: 0.001)
- `--train_split`: Train/validation split ratio (default: 0.8)
- `--adaptive_sampling`: Use adaptive spatial sampling for graph edges (improves gradient capture)
- `--sampling_radius`: Radius for adaptive sampling (default: auto-computed)
- `--normalize`: Enable feature normalization
- `--normalize_per_field`: Normalize each field separately (recommended)

**Note:** The method-based implementation uses a fixed 6-time-step input sequence. The model automatically handles sequence flattening.

### Prediction

**Important:** Activate the virtual environment first:
```bash
source venv/bin/activate  # On macOS/Linux
```

Make predictions with a trained model:
```bash
python predict_method.py --checkpoint checkpoints_method/best_model.pt --data_dir BFS-OpenFOAM-data
```

Arguments:
- `--checkpoint`: Path to model checkpoint
- `--data_dir`: Path to OpenFOAM data directory
- `--time_dir`: Specific time directory to predict (optional)
- `--output_dir`: Directory to save predictions (default: predictions_method)
- `--include_concentration`: Include concentration field if available

### Visualization

#### Contour Plots (Pressure & Velocity in X-Y Coordinates)

To plot contour plots showing spatial distribution of pressure and velocity fields:

```bash
python plot_contours.py --checkpoint checkpoints_method/best_model.pt --data_dir BFS-OpenFOAM-data
```

This creates:
- **Pressure contours**: Vertically stacked comparison of OpenFOAM pressure, model prediction, and percentage error
- **Velocity contours**: Vertically stacked comparison of OpenFOAM velocity magnitude, model prediction, and percentage error
- All plots show spatial distribution in x-y coordinates with contour lines
- **Domain masking**: Uses Delaunay triangulation to preserve sharp boundaries and square corners
- **Same colorbar scale**: OpenFOAM and prediction use identical scales for direct comparison
- **Error in percentage**: Error plots show percentage error for better interpretability

Options:
- `--time_dir`: Specific time directory to plot (default: validation time step)
- `--output_dir`: Directory to save plots (default: contour_plots)
- `--levels`: Number of contour levels (default: 30)
- `--include_concentration`: Include concentration field if available

#### Field Comparison Plots (Pressure & Velocity)

To plot pressure and velocity from both OpenFOAM data and trained model results with error analysis:

```bash
python plot_fields.py --checkpoint checkpoints_method/best_model.pt --data_dir BFS-OpenFOAM-data
```

This creates:
- **Pressure comparison**: Scatter plots, error distributions, R² scores for pressure
- **Velocity comparison**: Velocity magnitude and component-wise (u, v) analysis
- **Error summary**: Comprehensive error statistics and comparisons

Options:
- `--time_dir`: Specific time directory to plot (default: validation time step)
- `--output_dir`: Directory to save plots (default: field_plots)

#### Advanced Visualizations

For comprehensive visualizations with multiple plot types:

```bash
python visualize.py --checkpoint checkpoints_method/best_model.pt --data_dir BFS-OpenFOAM-data --all
```

This creates:
- **Field comparison plots**: Scatter plots, error distributions, R² scores
- **Component-wise plots**: Separate analysis for u, v components
- **Vector field plots**: 2D velocity field visualizations with quiver plots

Options:
- `--all`: Create all visualization types
- `--visualize_field`: Create field comparison plots
- `--visualize_components`: Create component-wise plots
- `--visualize_vectors`: Create vector field plots
- `--time_dir`: Specific time directory to visualize
- `--output_dir`: Directory to save visualizations (default: visualizations)

## Model Architecture

### Method-Based FlowGNN

The implementation strictly follows the method specification:

- **Input**: 24 features (6 time steps × 4 fields: [c, p, u, v])
- **Architecture**: 
  - Alternating single-head and multi-head GAT layers
  - Multi-head attention with 4 heads (K and Q dimension = 1)
  - Residual connections between layers
  - LeakyReLU activation
- **Output**: 4 features ([c, p, u, v]) for next time step
- **Loss**: MSE (`L = ||y_pred - y_CFD||_2^2`)
- **Evaluation**: L2 relative error (`||φ_pred - φ_true||_2 / ||φ_true||_2`)

### Adaptive Spatial Sampling

The graph construction supports **adaptive spatial sampling**:

- **Formula**: `ne(i) = { j | (x_i − x_j)² + (y_i − y_j)² ≤ r }`
- **Purpose**: Captures multi-scale gradient information, especially in regions with large gradient changes (near walls, obstacles)
- **Benefits**: 
  - Prevents jitter in flow fields with large gradient changes
  - Aggregates information from many neighbor nodes in high-gradient regions
  - Better perception of drastic gradient changes

**Usage:**
```bash
python train_method.py --data_dir BFS-OpenFOAM-data --epochs 50 --adaptive_sampling
```

Or with custom radius:
```bash
python train_method.py --data_dir BFS-OpenFOAM-data --epochs 50 --adaptive_sampling --sampling_radius 0.002
```

## Data Format

The parser expects OpenFOAM field files with:
- **Concentration** (optional): Scalar field `c` or `s`
- **Pressure**: Scalar field `p`
- **Velocity**: Vector field `U` (extracts u and v components)

Each time directory should contain field files with `internalField` data. The method uses 6 consecutive time steps as input to predict the next time step.

## Output

Training produces:
- Model checkpoints in `checkpoints_method/` directory
- Training curves plot (`training_curves.png`)
- L2 relative error metrics

Prediction produces:
- NumPy arrays with predictions and ground truth
- L2 relative error computation

Visualization produces:
- Contour plots in `contour_plots/` directory
- Field comparison plots in `field_plots/` directory
- Advanced visualizations in `visualizations/` directory

## Technical Details

- **Mesh connectivity**: Built from `owner` and `neighbour` arrays
- **Graph edges**: Internal faces create bidirectional edges, or adaptive spatial sampling
- **Node features**: [c, p, u, v] where c=concentration, p=pressure, u=x-velocity, v=y-velocity
- **Input sequence**: Fixed 6 time steps, flattened to 24 features per node
- **Cell centers**: Computed accurately from mesh geometry (faces and points)
- **Prediction**: Model predicts the next time step (t+1) from 6 previous time steps (t-6 to t-1)
- **Domain masking**: Contour plots use Delaunay triangulation to preserve sharp boundaries
- **GAT attention**: Exact formula with Q, K, V projections and LeakyReLU activation
- **Multi-head attention**: 4 heads with dimension 1 for K and Q

## Quick Start

**Training:**
```bash
source venv/bin/activate
python train_method.py --data_dir BFS-OpenFOAM-data --epochs 100 --model_type temporal --normalize --normalize_per_field --adaptive_sampling
```

**Visualization:**
```bash
# Contour plots (pressure & velocity)
python plot_contours.py --checkpoint checkpoints_method/best_model.pt --data_dir BFS-OpenFOAM-data

# Field comparison
python plot_fields.py --checkpoint checkpoints_method/best_model.pt --data_dir BFS-OpenFOAM-data
```

**Update Visualization (After Retraining):**
```bash
# Simply run plot_contours.py again with the new checkpoint
python plot_contours.py --checkpoint checkpoints_method/best_model.pt --data_dir BFS-OpenFOAM-data --time_dir 0.096
```

For detailed instructions, see [QUICK_START.md](QUICK_START.md).

## Documentation

- [METHOD_SUMMARY.md](METHOD_SUMMARY.md) - Complete method and equation summary
- [QUICK_START.md](QUICK_START.md) - Quick reference for training and visualization
- [README_METHOD.md](README_METHOD.md) - Detailed method-based implementation guide

## File Structure

```
GNN-BFS/
├── train_method.py              # Training script (method-based)
├── predict_method.py            # Prediction script (method-based)
├── gnn_model_method.py          # GNN model (method-based)
├── graph_constructor_method.py  # Graph construction (method-based)
├── attention_method.py          # Attention layers (method-based)
├── dataset_method.py            # Dataset (method-based)
├── plot_contours.py             # Contour plot visualization
├── plot_fields.py               # Field comparison visualization
├── visualize.py                 # Advanced visualization
├── openfoam_parser.py           # OpenFOAM data parser
├── normalization.py             # Feature normalization
├── requirements.txt             # Python dependencies
├── README                       # This file
├── METHOD_SUMMARY.md            # Method specification
├── QUICK_START.md               # Quick start guide
└── README_METHOD.md             # Method implementation details
```

## Important Notes

- **Fixed input sequence**: The method uses exactly 6 previous time steps. Ensure your data has at least 7 time directories (6 for input + 1 for target).
- **Feature order**: Features are always [c, p, u, v]. If concentration is not available, it defaults to zeros.
- **Checkpoint location**: Method-based models save to `checkpoints_method/` directory.
- **Normalization**: Recommended to use `--normalize --normalize_per_field` for better training stability.
